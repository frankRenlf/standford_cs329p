{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "colab": {
   "name": "hw1_v2.ipynb",
   "provenance": [],
   "collapsed_sections": []
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jRbuIIjtMMFj"
   },
   "source": [
    "# Homework 1 for CS 329P\n",
    "\n",
    "**Authors**: YOUR_NAMES\n",
    "\n",
    "**Emails**: YOUR_IDS@stanford.edu\n",
    "\n",
    "**Submission.** Please insert your names and emails above, save your code in this notebook, and explain what you are doing along with your findings in text cells. You can think of it as a technical report with code. Before submission, please use `Kernel -> Restart & Run All` in the Jupyter menu to verify your code is runnable and save all outputs. Afterwards, you can either upload your raw notebook (`hw1.ipynb`) or an exported PDF version to the `Homework 1` assignment in Canvas. \n",
    "\n",
    "\n",
    "In this homework, we will train a house sales price predictor on the data we scraped previously. The purpose of this homework is to let you practice different techniques that you can use to preprocess raw data. Your job is to obtain the best root mean squared logarithmic error (RMSLE) on the test dataset. To make your job easy, we provide sample code to train a model to report RMSLE and a list of ideas you can explore.\n",
    "\n",
    "**Note**: You can use either local runtimes to complete this assignment, or a hosted runtime (with GPU) on Colab. The second option generally runs faster. If using a local runtime, make sure that your Python version is less than 3.9 but at least 3.6, or you may have issues installing Autogluon. If using a runtime hosted on Colab, you can use the File Explorer pane on the left to upload the `house_sales.ftr` file. Make sure to wait until the file finishes uploading before running the next code block.\n",
    "\n",
    "Additionally, if using a local runtime, please refer to the [AG document](https://auto.gluon.ai/stable/index.html#installation) for info on how to install autogluon. \n",
    "\n",
    "## Prepare Data \n",
    "\n",
    "Let's first read in the dataset we used in our [Exploratory Data Analysis (EDA)](https://c.d2l.ai/stanford-cs329p/_static/notebooks/cs329p_notebook_eda.slides.html). Note that we use the [`feather` format](https://arrow.apache.org/docs/python/feather.html), which is faster to read than CSV but uses more disk space. The file `home_sales.ftr` can be downloaded from the Assignments folder in Canvas.\n",
    "\n",
    "Just for your information, it is generated with:\n",
    "\n",
    "```python\n",
    "data = pd.read_csv('house_sales.zip', dtype='unicode')\n",
    "data.to_feather('house_sales.ftr')\n",
    "```\n",
    "\n",
    "The following code needs at least 2GB memory. If using a local runtime, please make sure your machine has enough memory. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "YpsTjkMaMMFk",
    "ExecuteTime": {
     "end_time": "2023-09-01T07:18:41.502936Z",
     "start_time": "2023-09-01T07:18:39.265312Z"
    }
   },
   "source": [
    "# Run the following line once to install. You may need to restart your runtime afterwards:\n",
    "# !pip3 install numpy pandas autogluon mxnet --upgrade\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# print(\"NumPy 版本:\", np.__version__)\n",
    "data = pd.read_feather('../data/house_sales.ftr')\n"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "mi5vrBMMKn-X",
    "ExecuteTime": {
     "end_time": "2023-09-01T07:18:41.537488Z",
     "start_time": "2023-09-01T07:18:41.503099Z"
    }
   },
   "source": [
    "import scipy\n",
    "import numpy as np\n",
    "scipy.__version__, np.__version__"
   ],
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "('1.11.2', '1.24.4')"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wlvsGd0AMMFl"
   },
   "source": [
    "We select a few common columns to make our training fast. You need to select more columns to make your model more accurate. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "vMIZGUkiMMFl",
    "ExecuteTime": {
     "end_time": "2023-09-01T07:18:41.550036Z",
     "start_time": "2023-09-01T07:18:41.538843Z"
    }
   },
   "source": [
    "df = data[['Sold Price', 'Sold On', 'Type', 'Year built', 'Bedrooms', 'Bathrooms']].copy()\n",
    "# uncomment the below line to save memory\n",
    "# del data"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M025p8ZOMMFl"
   },
   "source": [
    "We copy the code from EDA to convert `Sold Price` to numerical values, which is our prediction target. We also remove examples whose prices are too high or too low."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "QEtKW8aZMMFl",
    "ExecuteTime": {
     "end_time": "2023-09-01T07:18:41.699035Z",
     "start_time": "2023-09-01T07:18:41.551199Z"
    }
   },
   "source": [
    "c = 'Sold Price'\n",
    "if c in df.select_dtypes('object').columns:\n",
    "    df.loc[:,c] = np.log10(\n",
    "            pd.to_numeric(df[c].replace(r'[$,-]', '', regex=True)) + 1)\n",
    "df = df[(df['Sold Price'] >= 4 ) & (df['Sold Price'] <= 8 )]"
   ],
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zv/7_nb_lnx5llfxwncr2x_6tvh0000gn/T/ipykernel_37925/1326071105.py:3: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df.loc[:,c] = np.log10(\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GwS6XYWAMMFm"
   },
   "source": [
    "We use the house sales between 2021-2-15 and 2021-3-1 as our test data. You can use any example before 2021-2-15, but not after. In other words, we pretend we are launching our model on 2021-2-15 and testing it for 2 weeks. Here we only use sales in 2021 for fast training, but you can use more to improve accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8HA0DTInMMFm",
    "ExecuteTime": {
     "end_time": "2023-09-01T07:18:41.738946Z",
     "start_time": "2023-09-01T07:18:41.704360Z"
    }
   },
   "source": [
    "test_start, test_end = pd.Timestamp(2021, 2, 15), pd.Timestamp(2021, 3, 1)\n",
    "train_start = pd.Timestamp(2021, 1, 1)\n",
    "df['Sold On'] = pd.to_datetime(df['Sold On'], errors='coerce')\n",
    "train = df[(df['Sold On'] >= train_start) & (df['Sold On'] < test_start)]\n",
    "test = df[(df['Sold On'] >= test_start) & (df['Sold On'] < test_end)]\n",
    "train.shape, test.shape"
   ],
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "((24872, 6), (11510, 6))"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AH-Gx95nMMFn"
   },
   "source": [
    "Define our evaluation metric. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "FP0f3vqNMMFn",
    "ExecuteTime": {
     "end_time": "2023-09-01T07:18:41.743416Z",
     "start_time": "2023-09-01T07:18:41.738554Z"
    }
   },
   "source": [
    "def rmsle(y_hat, y):\n",
    "    # we already used log prices before, so we only need to compute RMSE\n",
    "    return sum((y_hat - y)**2 / len(y))**0.5"
   ],
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fXFkQrUUMMFn"
   },
   "source": [
    "## AutoGluon Baseline\n",
    "\n",
    "We provide a baseline model trained by AutoGluon (AG). AG is an automl tool that performs automatic feature engineering, model selections, and ensemble. You are welcome to use any model and tool in achieving the best results possible in your homework. However, we recommend that you reuse the following training code so that you can focus on data preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": true,
    "id": "JPc8RXxJMMFn",
    "ExecuteTime": {
     "end_time": "2023-09-01T07:20:06.570733Z",
     "start_time": "2023-09-01T07:18:41.741660Z"
    }
   },
   "source": [
    "from autogluon.tabular import TabularPredictor\n",
    "    \n",
    "label = 'Sold Price'    \n",
    "predictor = TabularPredictor(label=label).fit(train)"
   ],
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20230901_071844/\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20230901_071844/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.9.17\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 22.6.0: Wed Jul  5 22:21:53 PDT 2023; root:xnu-8796.141.3~6/RELEASE_ARM64_T6020\n",
      "Disk Space Avail:   825.31 GB / 994.66 GB (83.0%)\n",
      "Train Data Rows:    24872\n",
      "Train Data Columns: 5\n",
      "Label Column: Sold Price\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (7.546542675816042, 4.000043427276863, 5.75084, 0.39719)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    14831.41 MB\n",
      "\tTrain Data (Original)  Memory Usage: 6.15 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting DatetimeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['Bedrooms']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 36\n",
      "\t\tWarning: Due to memory constraints, ngram feature count is being reduced. Allocate more memory to maximize model quality.\n",
      "\t\tReducing Vectorizer vocab size from 36 to 17 to avoid OOM error\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('datetime', [])                   : 1 | ['Sold On']\n",
      "\t\t('object', [])                     : 2 | ['Type', 'Bathrooms']\n",
      "\t\t('object', ['datetime_as_object']) : 1 | ['Year built']\n",
      "\t\t('object', ['text'])               : 1 | ['Bedrooms']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    :  2 | ['Type', 'Bathrooms']\n",
      "\t\t('category', ['text_as_category'])  :  1 | ['Bedrooms']\n",
      "\t\t('int', ['binned', 'text_special']) : 10 | ['Bedrooms.char_count', 'Bedrooms.word_count', 'Bedrooms.capital_ratio', 'Bedrooms.lower_ratio', 'Bedrooms.digit_ratio', ...]\n",
      "\t\t('int', ['datetime_as_int'])        :  8 | ['Sold On', 'Sold On.month', 'Sold On.day', 'Sold On.dayofweek', 'Year built', ...]\n",
      "\t\t('int', ['text_ngram'])             :  7 | ['__nlp__.bedroom', '__nlp__.bedroom on', '__nlp__.closet', '__nlp__.floor', '__nlp__.master', ...]\n",
      "\t0.5s = Fit runtime\n",
      "\t5 features in original data used to generate 28 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 2.27 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.5s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 22384, Val Rows: 2488\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t-0.3932\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.62s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t-0.3976\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t-0.2876\t = Validation score   (-root_mean_squared_error)\n",
      "\t7.07s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t-0.2885\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.54s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t-0.3079\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.93s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-0.286\t = Validation score   (-root_mean_squared_error)\n",
      "\t9.5s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-0.3043\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.13s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t-0.2906\t = Validation score   (-root_mean_squared_error)\n",
      "\t13.65s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-0.2881\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.2s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-0.2914\t = Validation score   (-root_mean_squared_error)\n",
      "\t29.88s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t-0.2883\t = Validation score   (-root_mean_squared_error)\n",
      "\t8.28s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-0.2848\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.09s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 82.16s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230901_071844/\")\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LpeILz5WMMFn"
   },
   "source": [
    "Test the performance of each model. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "1as6hzTCMMFn",
    "ExecuteTime": {
     "end_time": "2023-09-01T07:20:07.981672Z",
     "start_time": "2023-09-01T07:20:06.572586Z"
    }
   },
   "source": [
    "predictor.leaderboard(test, silent=True)"
   ],
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "                  model  score_test  score_val  pred_time_test  pred_time_val  \\\n0            LightGBMXT   -0.264573  -0.287632        0.059081       0.014158   \n1       NeuralNetFastAI   -0.268273  -0.290594        0.086652       0.024421   \n2         LightGBMLarge   -0.268721  -0.288314        0.026853       0.007031   \n3              LightGBM   -0.270316  -0.288493        0.046828       0.009970   \n4        NeuralNetTorch   -0.273075  -0.291414        0.043024       0.010337   \n5         ExtraTreesMSE   -0.281389  -0.304345        0.187538       0.041746   \n6   WeightedEnsemble_L2   -0.288208  -0.284793        0.348478       0.068444   \n7              CatBoost   -0.304060  -0.286025        0.053306       0.005385   \n8               XGBoost   -0.325221  -0.288091        0.063323       0.010819   \n9       RandomForestMSE   -0.349723  -0.307923        0.172403       0.055255   \n10       KNeighborsUnif   -0.417010  -0.393175        0.425203       0.094492   \n11       KNeighborsDist   -0.417270  -0.397646        0.147812       0.034014   \n\n     fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n0    7.073444                 0.059081                0.014158   \n1   13.651411                 0.086652                0.024421   \n2    8.281847                 0.026853                0.007031   \n3    5.544618                 0.046828                0.009970   \n4   29.884430                 0.043024                0.010337   \n5    1.131568                 0.187538                0.041746   \n6   42.805013                 0.001287                0.000157   \n7    9.500134                 0.053306                0.005385   \n8    2.197018                 0.063323                0.010819   \n9    2.928293                 0.172403                0.055255   \n10   0.618887                 0.425203                0.094492   \n11   0.005980                 0.147812                0.034014   \n\n    fit_time_marginal  stack_level  can_infer  fit_order  \n0            7.073444            1       True          3  \n1           13.651411            1       True          8  \n2            8.281847            1       True         11  \n3            5.544618            1       True          4  \n4           29.884430            1       True         10  \n5            1.131568            1       True          7  \n6            0.091863            2       True         12  \n7            9.500134            1       True          6  \n8            2.197018            1       True          9  \n9            2.928293            1       True          5  \n10           0.618887            1       True          1  \n11           0.005980            1       True          2  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>score_test</th>\n      <th>score_val</th>\n      <th>pred_time_test</th>\n      <th>pred_time_val</th>\n      <th>fit_time</th>\n      <th>pred_time_test_marginal</th>\n      <th>pred_time_val_marginal</th>\n      <th>fit_time_marginal</th>\n      <th>stack_level</th>\n      <th>can_infer</th>\n      <th>fit_order</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>LightGBMXT</td>\n      <td>-0.264573</td>\n      <td>-0.287632</td>\n      <td>0.059081</td>\n      <td>0.014158</td>\n      <td>7.073444</td>\n      <td>0.059081</td>\n      <td>0.014158</td>\n      <td>7.073444</td>\n      <td>1</td>\n      <td>True</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>NeuralNetFastAI</td>\n      <td>-0.268273</td>\n      <td>-0.290594</td>\n      <td>0.086652</td>\n      <td>0.024421</td>\n      <td>13.651411</td>\n      <td>0.086652</td>\n      <td>0.024421</td>\n      <td>13.651411</td>\n      <td>1</td>\n      <td>True</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>LightGBMLarge</td>\n      <td>-0.268721</td>\n      <td>-0.288314</td>\n      <td>0.026853</td>\n      <td>0.007031</td>\n      <td>8.281847</td>\n      <td>0.026853</td>\n      <td>0.007031</td>\n      <td>8.281847</td>\n      <td>1</td>\n      <td>True</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>LightGBM</td>\n      <td>-0.270316</td>\n      <td>-0.288493</td>\n      <td>0.046828</td>\n      <td>0.009970</td>\n      <td>5.544618</td>\n      <td>0.046828</td>\n      <td>0.009970</td>\n      <td>5.544618</td>\n      <td>1</td>\n      <td>True</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>NeuralNetTorch</td>\n      <td>-0.273075</td>\n      <td>-0.291414</td>\n      <td>0.043024</td>\n      <td>0.010337</td>\n      <td>29.884430</td>\n      <td>0.043024</td>\n      <td>0.010337</td>\n      <td>29.884430</td>\n      <td>1</td>\n      <td>True</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>ExtraTreesMSE</td>\n      <td>-0.281389</td>\n      <td>-0.304345</td>\n      <td>0.187538</td>\n      <td>0.041746</td>\n      <td>1.131568</td>\n      <td>0.187538</td>\n      <td>0.041746</td>\n      <td>1.131568</td>\n      <td>1</td>\n      <td>True</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>WeightedEnsemble_L2</td>\n      <td>-0.288208</td>\n      <td>-0.284793</td>\n      <td>0.348478</td>\n      <td>0.068444</td>\n      <td>42.805013</td>\n      <td>0.001287</td>\n      <td>0.000157</td>\n      <td>0.091863</td>\n      <td>2</td>\n      <td>True</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>CatBoost</td>\n      <td>-0.304060</td>\n      <td>-0.286025</td>\n      <td>0.053306</td>\n      <td>0.005385</td>\n      <td>9.500134</td>\n      <td>0.053306</td>\n      <td>0.005385</td>\n      <td>9.500134</td>\n      <td>1</td>\n      <td>True</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>XGBoost</td>\n      <td>-0.325221</td>\n      <td>-0.288091</td>\n      <td>0.063323</td>\n      <td>0.010819</td>\n      <td>2.197018</td>\n      <td>0.063323</td>\n      <td>0.010819</td>\n      <td>2.197018</td>\n      <td>1</td>\n      <td>True</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>RandomForestMSE</td>\n      <td>-0.349723</td>\n      <td>-0.307923</td>\n      <td>0.172403</td>\n      <td>0.055255</td>\n      <td>2.928293</td>\n      <td>0.172403</td>\n      <td>0.055255</td>\n      <td>2.928293</td>\n      <td>1</td>\n      <td>True</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>KNeighborsUnif</td>\n      <td>-0.417010</td>\n      <td>-0.393175</td>\n      <td>0.425203</td>\n      <td>0.094492</td>\n      <td>0.618887</td>\n      <td>0.425203</td>\n      <td>0.094492</td>\n      <td>0.618887</td>\n      <td>1</td>\n      <td>True</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>KNeighborsDist</td>\n      <td>-0.417270</td>\n      <td>-0.397646</td>\n      <td>0.147812</td>\n      <td>0.034014</td>\n      <td>0.005980</td>\n      <td>0.147812</td>\n      <td>0.034014</td>\n      <td>0.005980</td>\n      <td>1</td>\n      <td>True</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c1c0cM3QMMFo"
   },
   "source": [
    "Next, we compute the importance of each feature, along with several other metrics. It loooks like the `Sold On` feature is not very useful, likely because the houses in the test data were all sold late. You can choose to either remove such a feature, or find a way to extract a more useful presentation from it."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "RM9BVHmeMMFo",
    "ExecuteTime": {
     "end_time": "2023-09-01T07:20:12.262504Z",
     "start_time": "2023-09-01T07:20:07.956252Z"
    }
   },
   "source": [
    "predictor.feature_importance(test)"
   ],
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing feature importance via permutation shuffling for 5 features using 5000 rows with 5 shuffle sets...\n",
      "\t9.4s\t= Expected runtime (1.88s per shuffle set)\n",
      "\t4.29s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
     ]
    },
    {
     "data": {
      "text/plain": "            importance    stddev       p_value  n  p99_high   p99_low\nBathrooms     0.077595  0.002865  2.224927e-07  5  0.083493  0.071697\nType          0.071763  0.005169  3.208633e-06  5  0.082407  0.061119\nYear built    0.065390  0.002859  4.374602e-07  5  0.071277  0.059503\nBedrooms      0.012241  0.000821  2.413281e-06  5  0.013932  0.010551\nSold On       0.000174  0.000368  1.745692e-01  5  0.000932 -0.000584",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>importance</th>\n      <th>stddev</th>\n      <th>p_value</th>\n      <th>n</th>\n      <th>p99_high</th>\n      <th>p99_low</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Bathrooms</th>\n      <td>0.077595</td>\n      <td>0.002865</td>\n      <td>2.224927e-07</td>\n      <td>5</td>\n      <td>0.083493</td>\n      <td>0.071697</td>\n    </tr>\n    <tr>\n      <th>Type</th>\n      <td>0.071763</td>\n      <td>0.005169</td>\n      <td>3.208633e-06</td>\n      <td>5</td>\n      <td>0.082407</td>\n      <td>0.061119</td>\n    </tr>\n    <tr>\n      <th>Year built</th>\n      <td>0.065390</td>\n      <td>0.002859</td>\n      <td>4.374602e-07</td>\n      <td>5</td>\n      <td>0.071277</td>\n      <td>0.059503</td>\n    </tr>\n    <tr>\n      <th>Bedrooms</th>\n      <td>0.012241</td>\n      <td>0.000821</td>\n      <td>2.413281e-06</td>\n      <td>5</td>\n      <td>0.013932</td>\n      <td>0.010551</td>\n    </tr>\n    <tr>\n      <th>Sold On</th>\n      <td>0.000174</td>\n      <td>0.000368</td>\n      <td>1.745692e-01</td>\n      <td>5</td>\n      <td>0.000932</td>\n      <td>-0.000584</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DiL2aZB9MMFo"
   },
   "source": [
    "Finally, let's predict and evaluate the RMSLE."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "budOt2bGMMFo",
    "ExecuteTime": {
     "end_time": "2023-09-01T07:20:12.676371Z",
     "start_time": "2023-09-01T07:20:12.259900Z"
    }
   },
   "source": [
    "preds = predictor.predict(test.drop(columns=[label]))\n",
    "rmsle(preds, test[label])"
   ],
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "0.2882079884279717"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-21T17:10:23.648923Z",
     "start_time": "2021-09-21T17:10:16.162130Z"
    },
    "id": "abfuZLOWMMFo"
   },
   "source": [
    "## Your Solution\n",
    "\n",
    "Please include your solution in the following section. (You are welcome to edit and delete code in previous sections).\n",
    "\n",
    "Your goal is to train a model using the features in the original dataset that minimizes the RMSLE on the validation dataset. While the naïve model achieves an RMSLE of ~0.3, it is possible to achieve an RMSLE of less than 0.08 on the same dataset.\n",
    "\n",
    "Here is a list of ideas you could explore:\n",
    "\n",
    "- More features: We only selected a small set of columns to use in training. You can add more, especially the ones we examined in EDA.\n",
    "- Data type conversion: Most data columns are strings; you may need to convert them into numerical values.\n",
    "- Data cleaning: There are NAN and outliers sprinkled throughout the dataset. You should find ways to selectively filter and remove them.\n",
    "- More examples: We only included sales made in 2021; there is a large number of examples in previous years that you can also include."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Mvs8Kh0dDJRZ",
    "ExecuteTime": {
     "end_time": "2023-09-01T07:20:12.676558Z",
     "start_time": "2023-09-01T07:20:12.674024Z"
    }
   },
   "source": [
    "# YOUR SOLUTION HERE"
   ],
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n3yz5bBSMMFp"
   },
   "source": [
    "FIN"
   ]
  }
 ]
}
